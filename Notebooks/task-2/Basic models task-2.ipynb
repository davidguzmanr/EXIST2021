{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "negative-origin",
   "metadata": {},
   "source": [
    "# Modelos b√°sicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "opened-bangladesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import spacy\n",
    "from utils import preprocessing\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "from torchtext.data import Field\n",
    "from torchtext.vocab import GloVe, Vectors\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-quest",
   "metadata": {},
   "source": [
    "Ver [Trained Models & Pipelines](https://spacy.io/models) para los modelos de SpaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hired-stake",
   "metadata": {},
   "outputs": [],
   "source": [
    "en = spacy.load('en_core_web_md')\n",
    "\n",
    "def tokenize_en(sentence):\n",
    "    return [tok.text for tok in en.tokenizer(sentence)]\n",
    "\n",
    "es = spacy.load('es_core_news_md')\n",
    "\n",
    "def tokenize_es(sentence):\n",
    "    return [tok.text for tok in es.tokenizer(sentence)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accomplished-masters",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.vocab.GloVe at 0x7f8d2cf7a9e8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descargamos los embeddings\n",
    "GloVe(name='twitter.27B', dim=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "responsible-wednesday",
   "metadata": {},
   "source": [
    "## Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "likely-privilege",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2208, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('../../Data/EXIST2021_test.tsv', sep='\\t')\n",
    "test[test['language'] == 'en'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "japanese-congress",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_case</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>language</th>\n",
       "      <th>text</th>\n",
       "      <th>task1</th>\n",
       "      <th>task2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>1</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>she calls herself \" anti-feminazi \" how about ...</td>\n",
       "      <td>sexist</td>\n",
       "      <td>ideological-inequality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>3</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>wow , your skirt is very short . what is it's ...</td>\n",
       "      <td>sexist</td>\n",
       "      <td>objectification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>6</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>hello ... m raj ... m with good size and excel...</td>\n",
       "      <td>sexist</td>\n",
       "      <td>sexual-violence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>11</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>you weren't actually what ? this is not a pain...</td>\n",
       "      <td>sexist</td>\n",
       "      <td>ideological-inequality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>16</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>i don't know any feminists who think the way y...</td>\n",
       "      <td>sexist</td>\n",
       "      <td>ideological-inequality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test_case  id   source language  \\\n",
       "0   EXIST2021   1  twitter       en   \n",
       "2   EXIST2021   3  twitter       en   \n",
       "5   EXIST2021   6  twitter       en   \n",
       "10  EXIST2021  11  twitter       en   \n",
       "15  EXIST2021  16  twitter       en   \n",
       "\n",
       "                                                 text   task1  \\\n",
       "0   she calls herself \" anti-feminazi \" how about ...  sexist   \n",
       "2   wow , your skirt is very short . what is it's ...  sexist   \n",
       "5   hello ... m raj ... m with good size and excel...  sexist   \n",
       "10  you weren't actually what ? this is not a pain...  sexist   \n",
       "15  i don't know any feminists who think the way y...  sexist   \n",
       "\n",
       "                     task2  \n",
       "0   ideological-inequality  \n",
       "2          objectification  \n",
       "5          sexual-violence  \n",
       "10  ideological-inequality  \n",
       "15  ideological-inequality  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../../Data/EXIST2021_training.tsv', sep='\\t')\n",
    "# train = pd.read_csv('../../Data/EXIST2021_training_spell_checked.csv', sep=',')\n",
    "train = train[train['task1'] == 'sexist']\n",
    "\n",
    "# Un simple pre-procesamiento\n",
    "train['text'] = train['text'].apply(lambda text: preprocessing.preprocess(text))\n",
    "\n",
    "train_en = train[train['language'] == 'en']\n",
    "train_es = train[train['language'] == 'es']\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "prerequisite-fossil",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_case</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>language</th>\n",
       "      <th>text</th>\n",
       "      <th>task1</th>\n",
       "      <th>task2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>6980</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>lol ! \" this behavior of not letting men tell ...</td>\n",
       "      <td>sexist</td>\n",
       "      <td>ideological-inequality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>6981</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>rights ? i mean yeah most women especially the...</td>\n",
       "      <td>sexist</td>\n",
       "      <td>ideological-inequality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>6985</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>stop regarding women as animals who forget tht...</td>\n",
       "      <td>sexist</td>\n",
       "      <td>ideological-inequality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>6986</td>\n",
       "      <td>gab</td>\n",
       "      <td>en</td>\n",
       "      <td>yeah , it is rough , but not for women . marri...</td>\n",
       "      <td>sexist</td>\n",
       "      <td>objectification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>6989</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>you were publicly harassing a girl by constant...</td>\n",
       "      <td>sexist</td>\n",
       "      <td>misogyny-non-sexual-violence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test_case    id   source language  \\\n",
       "2   EXIST2021  6980  twitter       en   \n",
       "3   EXIST2021  6981  twitter       en   \n",
       "7   EXIST2021  6985  twitter       en   \n",
       "8   EXIST2021  6986      gab       en   \n",
       "11  EXIST2021  6989  twitter       en   \n",
       "\n",
       "                                                 text   task1  \\\n",
       "2   lol ! \" this behavior of not letting men tell ...  sexist   \n",
       "3   rights ? i mean yeah most women especially the...  sexist   \n",
       "7   stop regarding women as animals who forget tht...  sexist   \n",
       "8   yeah , it is rough , but not for women . marri...  sexist   \n",
       "11  you were publicly harassing a girl by constant...  sexist   \n",
       "\n",
       "                           task2  \n",
       "2         ideological-inequality  \n",
       "3         ideological-inequality  \n",
       "7         ideological-inequality  \n",
       "8                objectification  \n",
       "11  misogyny-non-sexual-violence  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('../../Data/EXIST2021_test.tsv', sep='\\t')\n",
    "# test = pd.read_csv('../../Data/EXIST2021_test_spell_checked.csv', sep=',')\n",
    "test = test[test['task1'] == 'sexist']\n",
    "\n",
    "\n",
    "# Un simple pre-procesamiento\n",
    "test['text'] = test['text'].apply(lambda text: preprocessing.preprocess(text))\n",
    "\n",
    "test_en = test[test['language'] == 'en']\n",
    "test_es = test[test['language'] == 'es']\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "impressive-congo",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(train['task2'])\n",
    "\n",
    "target_names = label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bridal-better",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'incredible ! aaa :D beautiful ! but i laughed sooo much when i read about you drifting in your wheelchair . i can just picture it lol'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '@AurelieGuiboud Incredible! AAAA :D Beautiful!But I laughed sooooooo much when I read about you drifting in your wheelchair.I can just picture it  https://t.co/uvl5HhbmbR lol'\n",
    "preprocessing.preprocess(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attended-giant",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-stocks",
   "metadata": {},
   "source": [
    "### Baseline (tf-idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-viking",
   "metadata": {},
   "source": [
    "#### English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "restricted-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el vectorizer\n",
    "vectorizer_en = TfidfVectorizer(analyzer='word', stop_words=None, lowercase=True)\n",
    "vectorizer_en.fit(train_en['text'])\n",
    "\n",
    "# Transformamos\n",
    "X_train_en = vectorizer_en.transform(train_en['text'])\n",
    "X_test_en = vectorizer_en.transform(test_en['text'])\n",
    "\n",
    "y_train_en = label_encoder.transform(train_en['task2'])\n",
    "y_test_en = label_encoder.transform(test_en['task2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "economic-weather",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.77 s, sys: 7.58 s, total: 10.3 s\n",
      "Wall time: 679 ms\n",
      "                              precision    recall  f1-score   support\n",
      "\n",
      "      ideological-inequality       0.61      0.76      0.68       333\n",
      "misogyny-non-sexual-violence       0.59      0.42      0.49       215\n",
      "             objectification       0.63      0.32      0.42       150\n",
      "             sexual-violence       0.60      0.61      0.61       198\n",
      "      stereotyping-dominance       0.49      0.58      0.53       262\n",
      "\n",
      "                    accuracy                           0.58      1158\n",
      "                   macro avg       0.58      0.54      0.55      1158\n",
      "                weighted avg       0.58      0.58      0.57      1158\n",
      "\n",
      "F1-score: 0.5464\n"
     ]
    }
   ],
   "source": [
    "clf_en = LogisticRegression(max_iter=1000)\n",
    "%time clf_en.fit(X_train_en, y_train_en)\n",
    "\n",
    "y_pred_en = clf_en.predict(X_test_en)\n",
    "\n",
    "print(classification_report(y_test_en, y_pred_en, target_names=target_names))\n",
    "print(f'F1-score: {round(f1_score(y_test_en, y_pred_en, average=\"macro\"), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dietary-intensity",
   "metadata": {},
   "source": [
    "#### Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "german-fiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el vectorizer\n",
    "vectorizer_es = TfidfVectorizer(analyzer='word', stop_words=None, lowercase=True)\n",
    "vectorizer_es.fit(train_es['text'])\n",
    "\n",
    "# Transformamos\n",
    "X_train_es = vectorizer_es.transform(train_es['text'])\n",
    "X_test_es = vectorizer_es.transform(test_es['text'])\n",
    "\n",
    "y_train_es = label_encoder.transform(train_es['task2'])\n",
    "y_test_es = label_encoder.transform(test_es['task2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "wicked-scope",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.69 s, sys: 7.01 s, total: 9.7 s\n",
      "Wall time: 707 ms\n",
      "                              precision    recall  f1-score   support\n",
      "\n",
      "      ideological-inequality       0.56      0.85      0.68       288\n",
      "misogyny-non-sexual-violence       0.54      0.52      0.53       257\n",
      "             objectification       0.65      0.33      0.44       174\n",
      "             sexual-violence       0.92      0.24      0.38       202\n",
      "      stereotyping-dominance       0.43      0.63      0.51       202\n",
      "\n",
      "                    accuracy                           0.55      1123\n",
      "                   macro avg       0.62      0.52      0.51      1123\n",
      "                weighted avg       0.61      0.55      0.52      1123\n",
      "\n",
      "F1-score: 0.5077\n"
     ]
    }
   ],
   "source": [
    "clf_es = LogisticRegression(max_iter=1000)\n",
    "%time clf_es.fit(X_train_es, y_train_es)\n",
    "\n",
    "y_pred_es = clf_es.predict(X_test_es)\n",
    "\n",
    "print(classification_report(y_test_es, y_pred_es, target_names=target_names))\n",
    "print(f'F1-score: {round(f1_score(y_test_es, y_pred_es, average=\"macro\"), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-entity",
   "metadata": {},
   "source": [
    "#### Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "exempt-morning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "      ideological-inequality       0.58      0.80      0.68       621\n",
      "misogyny-non-sexual-violence       0.56      0.47      0.51       472\n",
      "             objectification       0.64      0.33      0.43       324\n",
      "             sexual-violence       0.67      0.42      0.52       400\n",
      "      stereotyping-dominance       0.46      0.61      0.52       464\n",
      "\n",
      "                    accuracy                           0.56      2281\n",
      "                   macro avg       0.58      0.53      0.53      2281\n",
      "                weighted avg       0.58      0.56      0.55      2281\n",
      "\n",
      "F1-score: 0.533\n"
     ]
    }
   ],
   "source": [
    "y_test = np.hstack((y_test_en, y_test_es))\n",
    "y_pred = np.hstack((y_pred_en, y_pred_es))\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "print(f'F1-score: {round(f1_score(y_test, y_pred, average=\"macro\"), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-sullivan",
   "metadata": {},
   "source": [
    "### Promedio de vectores de palabras con GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-jenny",
   "metadata": {},
   "source": [
    "Para los embeddings en ingl√©s usar√© los que est√°n pre-entrenados con el corpus de Twitter, pues los datos de esta tarea tambi√©n son de Twitter.\n",
    "\n",
    "Debido a que Torchtext s√≥lo tiene por defecto embeddings en ingl√©s hay que hacer otras cosas para cargar los que est√°n en espa√±ol. Primero, hay que descargarlos de [GloVe Spanish](http://dcc.uchile.cl/~jperez/word-embeddings/glove-sbwc.i25.vec.gz) y ponerlos en la carpeta `.vector_cache` del directorio actual. Para ver otros embeddings pre-entrenados en espa√±ol ver [spanish-word-embeddings](https://github.com/dccuchile/spanish-word-embeddings).\n",
    "\n",
    "Ver lo siguiente para algunos detalles de c√≥mo cargarlos para la capa de embeddings:\n",
    "\n",
    "- [Use pretrained embedding in Spanish with Torchtext](https://stackoverflow.com/questions/52224555/use-pretrained-embedding-in-spanish-with-torchtext)\n",
    "- [Handling German Text with torchtext](https://www.innoq.com/en/blog/handling-german-text-with-torchtext/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-ladder",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://dcc.uchile.cl/~jperez/word-embeddings/glove-sbwc.i25.vec.gz -P .vector_cache\n",
    "!gunzip .vector_cache/glove-sbwc.i25.vec.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "affected-antenna",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_vector(text, text_field, vocab):\n",
    "    \"\"\"\n",
    "    Promedia los vectores de palabras de un texto.\n",
    "    \"\"\"\n",
    "    vectors = np.array([vocab.vectors[vocab[token]].numpy() for token in text_field.preprocess(text)])\n",
    "    return np.mean(vectors, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-shape",
   "metadata": {},
   "source": [
    "#### English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "sonic-backup",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 1812),\n",
       " ('a', 1275),\n",
       " ('the', 1206),\n",
       " ('to', 1190),\n",
       " (',', 1174),\n",
       " ('you', 1076),\n",
       " ('i', 995),\n",
       " ('and', 964),\n",
       " ('#', 855),\n",
       " ('‚Äô', 745)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definimos c√≥mo se preprocesar√° el texto\n",
    "text_field_en = Field(tokenize=tokenize_en, lower=True)\n",
    "\n",
    "# Preprocesamos el texto\n",
    "preprocessed_train_text_en = train_en['text'].apply(lambda x: text_field_en.preprocess(x))\n",
    "preprocessed_test_text_en = test_en['text'].apply(lambda x: text_field_en.preprocess(x))\n",
    "\n",
    "# Contruimos el vocabulario\n",
    "text_field_en.build_vocab(preprocessed_train_text_en, vectors='glove.twitter.27B.200d', vectors_cache='.vector_cache')\n",
    "vocab_en = text_field_en.vocab\n",
    "vocab_en.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "smart-november",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1636/1636 [00:00<00:00, 6451.85it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_en = np.zeros(shape=(train_en.shape[0], 200))\n",
    "\n",
    "for i, text in tqdm(enumerate(train_en['text']), total=train_en.shape[0]):\n",
    "    X_train_en[i, :] = mean_vector(text, text_field_en, vocab_en)\n",
    "    \n",
    "y_train_en = label_encoder.transform(train_en['task2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "administrative-scanning",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1158/1158 [00:00<00:00, 5692.53it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test_en = np.zeros(shape=(test_en.shape[0], 200))\n",
    "\n",
    "for i, text in tqdm(enumerate(test_en['text']), total=test_en.shape[0]):\n",
    "    X_test_en[i, :] = mean_vector(text, text_field_en, vocab_en)\n",
    "    \n",
    "y_test_en = label_encoder.transform(test_en['task2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "following-frame",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.75 s, sys: 3.35 s, total: 5.09 s\n",
      "Wall time: 346 ms\n",
      "                              precision    recall  f1-score   support\n",
      "\n",
      "      ideological-inequality       0.58      0.68      0.63       333\n",
      "misogyny-non-sexual-violence       0.54      0.35      0.42       215\n",
      "             objectification       0.58      0.46      0.51       150\n",
      "             sexual-violence       0.57      0.63      0.60       198\n",
      "      stereotyping-dominance       0.47      0.52      0.50       262\n",
      "\n",
      "                    accuracy                           0.55      1158\n",
      "                   macro avg       0.55      0.53      0.53      1158\n",
      "                weighted avg       0.55      0.55      0.54      1158\n",
      "\n",
      "F1-score: 0.5319\n"
     ]
    }
   ],
   "source": [
    "clf_en = LogisticRegression(max_iter=1000)\n",
    "%time clf_en.fit(X_train_en, y_train_en)\n",
    "\n",
    "y_pred_en = clf_en.predict(X_test_en)\n",
    "\n",
    "print(classification_report(y_test_en, y_pred_en, target_names=target_names))\n",
    "print(f'F1-score: {round(f1_score(y_test_en, y_pred_en, average=\"macro\"), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-niagara",
   "metadata": {},
   "source": [
    "#### Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "female-journalism",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_es = Vectors('glove-sbwc.i25.vec', cache='.vector_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "supreme-voice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 2169),\n",
       " ('que', 2064),\n",
       " ('de', 1732),\n",
       " ('.', 1412),\n",
       " ('la', 1298),\n",
       " ('a', 1253),\n",
       " ('y', 1227),\n",
       " ('no', 1095),\n",
       " ('el', 927),\n",
       " ('las', 851)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definimos c√≥mo se preprocesar√° el texto\n",
    "text_field_es = Field(tokenize=tokenize_es, lower=True)\n",
    "\n",
    "# Preprocesamos el texto\n",
    "preprocessed_train_text_es = train_es['text'].apply(lambda x: text_field_es.preprocess(x))\n",
    "preprocessed_test_text_es = test_es['text'].apply(lambda x: text_field_es.preprocess(x))\n",
    "\n",
    "# Contruimos el vocabulario\n",
    "text_field_es.build_vocab(preprocessed_train_text_es, vectors=vectors_es)\n",
    "vocab_es = text_field_es.vocab\n",
    "vocab_es.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "completed-commission",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1741/1741 [00:00<00:00, 7682.87it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_es = np.zeros(shape=(train_es.shape[0], 300))\n",
    "\n",
    "for i, text in tqdm(enumerate(train_es['text']), total=train_es.shape[0]):\n",
    "    X_train_es[i, :] = mean_vector(text, text_field_es, vocab_es)\n",
    "    \n",
    "y_train_es = label_encoder.transform(train_es['task2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "frequent-radiation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1741/1741 [00:00<00:00, 7768.35it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_es = np.zeros(shape=(train_es.shape[0], 300))\n",
    "\n",
    "for i, text in tqdm(enumerate(train_es['text']), total=train_es.shape[0]):\n",
    "    X_train_es[i, :] = mean_vector(text, text_field_es, vocab_es)\n",
    "    \n",
    "y_train_es = label_encoder.transform(train_es['task2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "infinite-disabled",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1123/1123 [00:00<00:00, 7192.67it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test_es = np.zeros(shape=(test_es.shape[0], 300))\n",
    "\n",
    "for i, text in tqdm(enumerate(test_es['text']), total=test_es.shape[0]):\n",
    "    X_test_es[i, :] = mean_vector(text, text_field_es, vocab_es)\n",
    "    \n",
    "y_test_es = label_encoder.transform(test_es['task2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "artistic-savannah",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.1 s, sys: 3.73 s, total: 5.82 s\n",
      "Wall time: 378 ms\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.81      0.65       288\n",
      "           1       0.47      0.52      0.49       257\n",
      "           2       0.60      0.32      0.41       174\n",
      "           3       0.78      0.23      0.35       202\n",
      "           4       0.44      0.57      0.50       202\n",
      "\n",
      "    accuracy                           0.52      1123\n",
      "   macro avg       0.57      0.49      0.48      1123\n",
      "weighted avg       0.56      0.52      0.50      1123\n",
      "\n",
      "F1-score: 0.4818\n"
     ]
    }
   ],
   "source": [
    "clf_es = LogisticRegression(max_iter=1000)\n",
    "%time clf_es.fit(X_train_es, y_train_es)\n",
    "\n",
    "y_pred_es = clf_es.predict(X_test_es)\n",
    "\n",
    "print(classification_report(y_test_es, y_pred_es))\n",
    "print(f'F1-score: {round(f1_score(y_test_es, y_pred_es, average=\"macro\"), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-linux",
   "metadata": {},
   "source": [
    "#### Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ranging-penetration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "      ideological-inequality       0.56      0.74      0.64       621\n",
      "misogyny-non-sexual-violence       0.50      0.44      0.47       472\n",
      "             objectification       0.59      0.38      0.46       324\n",
      "             sexual-violence       0.61      0.42      0.50       400\n",
      "      stereotyping-dominance       0.46      0.54      0.50       464\n",
      "\n",
      "                    accuracy                           0.53      2281\n",
      "                   macro avg       0.54      0.51      0.51      2281\n",
      "                weighted avg       0.54      0.53      0.53      2281\n",
      "\n",
      "F1-score: 0.5139\n"
     ]
    }
   ],
   "source": [
    "y_test = np.hstack((y_test_en, y_test_es))\n",
    "y_pred = np.hstack((y_pred_en, y_pred_es))\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "print(f'F1-score: {round(f1_score(y_test, y_pred, average=\"macro\"), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fancy-consultation",
   "metadata": {},
   "source": [
    "### Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-priority",
   "metadata": {},
   "source": [
    "#### English"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuous-multiple",
   "metadata": {},
   "source": [
    "Al igual que los vectores usados en GloVe har√© que los embeddings the Doc2Vec tengan dimesi√≥n igual a 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "right-reform",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.54 s, sys: 819 ms, total: 9.36 s\n",
      "Wall time: 5.19 s\n"
     ]
    }
   ],
   "source": [
    "documents_en = [TaggedDocument(doc, [i]) for doc, i in zip(preprocessed_train_text_en, train_en['task2'])]\n",
    "%time doc2vec_en = Doc2Vec(documents_en, vector_size=200, window=5, min_count=1, workers=4, seed=42, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "macro-profit",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1636/1636 [00:03<00:00, 437.41it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_en = np.zeros(shape=(train_en.shape[0], 200))\n",
    "\n",
    "for i, text in tqdm(enumerate(train_en['text']), total=train_en.shape[0]):\n",
    "    X_train_en[i, :] = doc2vec_en.infer_vector(text_field_en.preprocess(text))\n",
    "    \n",
    "y_train_en = label_encoder.transform(train_en['task2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "heavy-sculpture",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1158/1158 [00:02<00:00, 452.84it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test_en = np.zeros(shape=(test_en.shape[0], 200))\n",
    "\n",
    "for i, text in tqdm(enumerate(test_en['text']), total=test_en.shape[0]):\n",
    "    X_test_en[i, :] = doc2vec_en.infer_vector(text_field_en.preprocess(text))\n",
    "    \n",
    "y_test_en = label_encoder.transform(test_en['task2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "offshore-candy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 624 ms, sys: 1.04 s, total: 1.67 s\n",
      "Wall time: 114 ms\n",
      "                              precision    recall  f1-score   support\n",
      "\n",
      "      ideological-inequality       0.54      0.45      0.49       333\n",
      "misogyny-non-sexual-violence       0.35      0.39      0.37       215\n",
      "             objectification       0.29      0.28      0.29       150\n",
      "             sexual-violence       0.38      0.38      0.38       198\n",
      "      stereotyping-dominance       0.37      0.42      0.40       262\n",
      "\n",
      "                    accuracy                           0.40      1158\n",
      "                   macro avg       0.39      0.38      0.38      1158\n",
      "                weighted avg       0.41      0.40      0.40      1158\n",
      "\n",
      "F1-score: 0.3842\n"
     ]
    }
   ],
   "source": [
    "clf_en = LogisticRegression(max_iter=1000)\n",
    "%time clf_en.fit(X_train_en, y_train_en)\n",
    "\n",
    "y_pred_en = clf_en.predict(X_test_en)\n",
    "\n",
    "print(classification_report(y_test_en, y_pred_en, target_names=target_names))\n",
    "print(f'F1-score: {round(f1_score(y_test_en, y_pred_en, average=\"macro\"), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-computer",
   "metadata": {},
   "source": [
    "#### Spanish\n",
    "Al igual que los vectores usados en GloVe har√© que los embeddings the Doc2Vec tengan dimesi√≥n igual a 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "muslim-alliance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.67 s, sys: 1.48 s, total: 11.1 s\n",
      "Wall time: 5.66 s\n"
     ]
    }
   ],
   "source": [
    "documents_es = [TaggedDocument(doc, [i]) for doc, i in zip(preprocessed_train_text_es, train_es['task2'])]\n",
    "%time doc2vec_es = Doc2Vec(documents_es, vector_size=300, window=5, min_count=1, workers=4, seed=42, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "peaceful-literature",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1741/1741 [00:03<00:00, 438.54it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_es = np.zeros(shape=(train_es.shape[0], 300))\n",
    "\n",
    "for i, text in tqdm(enumerate(train_es['text']), total=train_es.shape[0]):\n",
    "    X_train_es[i, :] = doc2vec_es.infer_vector(text_field_es.preprocess(text))\n",
    "    \n",
    "y_train_es = label_encoder.transform(train_es['task2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "engaged-lotus",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1123/1123 [00:02<00:00, 475.47it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test_es = np.zeros(shape=(test_es.shape[0], 300))\n",
    "\n",
    "for i, text in tqdm(enumerate(test_es['text']), total=test_es.shape[0]):\n",
    "    X_test_es[i, :] = doc2vec_es.infer_vector(text_field_es.preprocess(text))\n",
    "    \n",
    "y_test_es = label_encoder.transform(test_es['task2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "urban-birmingham",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 735 ms, sys: 1.28 s, total: 2.02 s\n",
      "Wall time: 134 ms\n",
      "                              precision    recall  f1-score   support\n",
      "\n",
      "      ideological-inequality       0.47      0.47      0.47       288\n",
      "misogyny-non-sexual-violence       0.34      0.42      0.38       257\n",
      "             objectification       0.32      0.37      0.35       174\n",
      "             sexual-violence       0.47      0.24      0.32       202\n",
      "      stereotyping-dominance       0.31      0.34      0.32       202\n",
      "\n",
      "                    accuracy                           0.38      1123\n",
      "                   macro avg       0.38      0.37      0.37      1123\n",
      "                weighted avg       0.39      0.38      0.37      1123\n",
      "\n",
      "F1-score: 0.3658\n"
     ]
    }
   ],
   "source": [
    "clf_es = LogisticRegression(max_iter=1000)\n",
    "%time clf_es.fit(X_train_es, y_train_es)\n",
    "\n",
    "y_pred_es = clf_es.predict(X_test_es)\n",
    "\n",
    "print(classification_report(y_test_es, y_pred_es, target_names=target_names))\n",
    "print(f'F1-score: {round(f1_score(y_test_es, y_pred_es, average=\"macro\"), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-immigration",
   "metadata": {},
   "source": [
    "#### Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "representative-background",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "      ideological-inequality       0.51      0.46      0.48       621\n",
      "misogyny-non-sexual-violence       0.34      0.41      0.37       472\n",
      "             objectification       0.31      0.33      0.32       324\n",
      "             sexual-violence       0.41      0.31      0.35       400\n",
      "      stereotyping-dominance       0.34      0.39      0.36       464\n",
      "\n",
      "                    accuracy                           0.39      2281\n",
      "                   macro avg       0.38      0.38      0.38      2281\n",
      "                weighted avg       0.40      0.39      0.39      2281\n",
      "\n",
      "F1-score: 0.3777\n"
     ]
    }
   ],
   "source": [
    "y_test = np.hstack((y_test_en, y_test_es))\n",
    "y_pred = np.hstack((y_pred_en, y_pred_es))\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "print(f'F1-score: {round(f1_score(y_test, y_pred, average=\"macro\"), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-frank",
   "metadata": {},
   "source": [
    "### sentence-BERT\n",
    "\n",
    "En [Pretrained Models](https://www.sbert.net/docs/pretrained_models.html) est√°n todos los modelos preentrenados que hay. Los modelos fuertes en una tarea, ser√°n d√©biles para otra tarea, por lo tanto, es importante seleccionar el modelo adecuado para cada tarea. Como no hay ninguno en espec√≠fico para la tarea de an√°lisis de sentimientos usar√© **paraphrase-distilroberta-base-v1**, el cual recomiendan para varias aplicaciones.\n",
    "\n",
    "**distiluse-base-multilingual-cased-v1:** Multilingual knowledge distilled version of multilingual Universal Sentence Encoder. Supports 15 languages: Arabic, Chinese, Dutch, English, French, German, Italian, Korean, Polish, Portuguese, Russian, Spanish, Turkish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "pleasant-exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descagamos el modelo\n",
    "model = SentenceTransformer('distiluse-base-multilingual-cased-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-disclaimer",
   "metadata": {},
   "source": [
    "#### English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "focal-landscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train_en = [' '.join(review) for review in preprocessed_train_text_en]\n",
    "sentences_test_en = [' '.join(review) for review in preprocessed_test_text_en]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "physical-enforcement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af83c47d1994c598163737849e7298a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.37 s, sys: 442 ms, total: 3.81 s\n",
      "Wall time: 3.29 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7f00666032d4660bfc71631a5b9ed92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.51 s, sys: 152 ms, total: 1.66 s\n",
      "Wall time: 1.25 s\n"
     ]
    }
   ],
   "source": [
    "# Cada embedding tiene dimensi√≥n igual a 768\n",
    "%time X_train_en = model.encode(sentences_train_en, show_progress_bar=True)\n",
    "%time X_test_en = model.encode(sentences_test_en, show_progress_bar=True)\n",
    "\n",
    "y_train_en = label_encoder.transform(train_en['task2'])\n",
    "y_test_en = label_encoder.transform(test_en['task2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "impossible-sterling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 671 ms, sys: 1.13 s, total: 1.8 s\n",
      "Wall time: 123 ms\n",
      "                              precision    recall  f1-score   support\n",
      "\n",
      "      ideological-inequality       0.68      0.69      0.69       333\n",
      "misogyny-non-sexual-violence       0.54      0.44      0.48       215\n",
      "             objectification       0.66      0.49      0.56       150\n",
      "             sexual-violence       0.61      0.68      0.64       198\n",
      "      stereotyping-dominance       0.57      0.69      0.62       262\n",
      "\n",
      "                    accuracy                           0.61      1158\n",
      "                   macro avg       0.61      0.60      0.60      1158\n",
      "                weighted avg       0.62      0.61      0.61      1158\n",
      "\n",
      "F1-score: 0.5999\n"
     ]
    }
   ],
   "source": [
    "clf_en = LogisticRegression(max_iter=1000)\n",
    "%time clf_en.fit(X_train_en, y_train_en)\n",
    "\n",
    "y_pred_en = clf_en.predict(X_test_en)\n",
    "\n",
    "print(classification_report(y_test_en, y_pred_en, target_names=target_names))\n",
    "print(f'F1-score: {round(f1_score(y_test_en, y_pred_en, average=\"macro\"), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-cowboy",
   "metadata": {},
   "source": [
    "#### Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "changed-pioneer",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train_es = [' '.join(review) for review in preprocessed_train_text_es]\n",
    "sentences_test_es = [' '.join(review) for review in preprocessed_test_text_es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "vocational-cloud",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05bedf5817d4deebc0623921a675803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.15 s, sys: 99.9 ms, total: 2.25 s\n",
      "Wall time: 1.68 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c27a0a8b4ec4830b07cdb8908d55f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.44 s, sys: 56.8 ms, total: 1.5 s\n",
      "Wall time: 1.12 s\n"
     ]
    }
   ],
   "source": [
    "# Cada embedding tiene dimensi√≥n igual a 768\n",
    "%time X_train_es = model.encode(sentences_train_es, show_progress_bar=True)\n",
    "%time X_test_es = model.encode(sentences_test_es, show_progress_bar=True)\n",
    "\n",
    "y_train_es = label_encoder.transform(train_es['task2'])\n",
    "y_test_es = label_encoder.transform(test_es['task2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "floral-thesaurus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 769 ms, sys: 1.57 s, total: 2.34 s\n",
      "Wall time: 156 ms\n",
      "                              precision    recall  f1-score   support\n",
      "\n",
      "      ideological-inequality       0.68      0.84      0.75       288\n",
      "misogyny-non-sexual-violence       0.52      0.60      0.56       257\n",
      "             objectification       0.70      0.48      0.57       174\n",
      "             sexual-violence       0.87      0.49      0.63       202\n",
      "      stereotyping-dominance       0.51      0.60      0.55       202\n",
      "\n",
      "                    accuracy                           0.62      1123\n",
      "                   macro avg       0.66      0.60      0.61      1123\n",
      "                weighted avg       0.65      0.62      0.62      1123\n",
      "\n",
      "F1-score: 0.6108\n"
     ]
    }
   ],
   "source": [
    "clf_es = LogisticRegression(max_iter=1000)\n",
    "%time clf_es.fit(X_train_es, y_train_es)\n",
    "\n",
    "y_pred_es = clf_es.predict(X_test_es)\n",
    "\n",
    "print(classification_report(y_test_es, y_pred_es, target_names=target_names))\n",
    "print(f'F1-score: {round(f1_score(y_test_es, y_pred_es, average=\"macro\"), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-inventory",
   "metadata": {},
   "source": [
    "#### Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "positive-internship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "      ideological-inequality       0.68      0.76      0.72       621\n",
      "misogyny-non-sexual-violence       0.53      0.53      0.53       472\n",
      "             objectification       0.68      0.48      0.57       324\n",
      "             sexual-violence       0.70      0.58      0.63       400\n",
      "      stereotyping-dominance       0.55      0.65      0.59       464\n",
      "\n",
      "                    accuracy                           0.62      2281\n",
      "                   macro avg       0.63      0.60      0.61      2281\n",
      "                weighted avg       0.62      0.62      0.62      2281\n",
      "\n",
      "F1-score: 0.6076\n"
     ]
    }
   ],
   "source": [
    "y_test = np.hstack((y_test_en, y_test_es))\n",
    "y_pred = np.hstack((y_pred_en, y_pred_es))\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "print(f'F1-score: {round(f1_score(y_test, y_pred, average=\"macro\"), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-virus",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "\n",
    "De los distintos modelos el mejor parece ser el de BERT que ha sido entrenado con varios idiomas.\n",
    "\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    ".tg .tg-amwm{font-weight:bold;text-align:center;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-amwm\" rowspan=\"2\">Model</th>\n",
    "    <th class=\"tg-amwm\" colspan=\"3\">Task-2 (F1 score)</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">English</td>\n",
    "    <td class=\"tg-baqh\">Spanish</td>\n",
    "    <td class=\"tg-baqh\">Total</td>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">tf-idf</td>\n",
    "    <td class=\"tg-baqh\">54.64</td>\n",
    "    <td class=\"tg-baqh\">50.77</td>\n",
    "    <td class=\"tg-baqh\">53.30</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">GloVe</td>\n",
    "    <td class=\"tg-baqh\">53.19</td>\n",
    "    <td class=\"tg-baqh\">48.18</td>\n",
    "    <td class=\"tg-baqh\">51.39</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">Doc2Vec</td>\n",
    "    <td class=\"tg-baqh\">38.18</td>\n",
    "    <td class=\"tg-baqh\">37.87</td>\n",
    "    <td class=\"tg-baqh\">38.41</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">sentence-BERT</td>\n",
    "    <td class=\"tg-baqh\">59.99</td>\n",
    "    <td class=\"tg-baqh\">61.08</td>\n",
    "    <td class=\"tg-baqh\">60.76</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>\n",
    "<!-- - Al hacer la clasificaci√≥n con el spell-check se obtiene:\n",
    "\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    ".tg .tg-amwm{font-weight:bold;text-align:center;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-amwm\" rowspan=\"2\">Model</th>\n",
    "    <th class=\"tg-amwm\" colspan=\"3\">Task-2 (F1 score)</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">English</td>\n",
    "    <td class=\"tg-baqh\">Spanish</td>\n",
    "    <td class=\"tg-baqh\">Total</td>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">tf-idf</td>\n",
    "    <td class=\"tg-baqh\">35.80</td>\n",
    "    <td class=\"tg-baqh\">34.92</td>\n",
    "    <td class=\"tg-baqh\">35.89</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">GloVe</td>\n",
    "    <td class=\"tg-baqh\">35.39</td>\n",
    "    <td class=\"tg-baqh\">34.46</td>\n",
    "    <td class=\"tg-baqh\">35.45</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">Doc2Vec</td>\n",
    "    <td class=\"tg-baqh\">29.96</td>\n",
    "    <td class=\"tg-baqh\">28.43</td>\n",
    "    <td class=\"tg-baqh\">29.46</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">sentence-BERT</td>\n",
    "    <td class=\"tg-baqh\">46.09</td>\n",
    "    <td class=\"tg-baqh\">42.10</td>\n",
    "    <td class=\"tg-baqh\">44.72</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table> -->\n",
    "\n",
    "- En realidad parece empeorar un poco con el spell-check, adem√°s de que es algo tardado hacerlo, por lo que mejor no usar√© el spell-check. \n",
    "- Por otro lado, hacer el pre-procesamiento parece ayudar un poco."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
