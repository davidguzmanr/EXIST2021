{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "reasonable-fellowship",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from torchtext.data import Field\n",
    "from torchtext.vocab import GloVe\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, f1_score\n",
    "\n",
    "import gdown\n",
    "from utils import preprocessing\n",
    "from utils.evaluation import DataSetText, SexismClassifier, infer\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-failure",
   "metadata": {},
   "source": [
    "# Evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strange-ticket",
   "metadata": {},
   "source": [
    "## Modelos\n",
    "\n",
    "Primero necesitamos descargar los modelos ya entrenados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "figured-variance",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "inside-coordinate",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://drive.google.com/uc?id=1AtE9iu5OWeTpYTeMa_xrCvsmSuGVyFdJ'\n",
    "output = 'models/sexism-classifier-task2.pt'\n",
    "\n",
    "gdown.download(url, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "binding-angel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "├─BertModel: 1-1                         --\n",
       "|    └─BertEmbeddings: 2-1               --\n",
       "|    |    └─Embedding: 3-1               81,315,072\n",
       "|    |    └─Embedding: 3-2               393,216\n",
       "|    |    └─Embedding: 3-3               1,536\n",
       "|    |    └─LayerNorm: 3-4               1,536\n",
       "|    |    └─Dropout: 3-5                 --\n",
       "|    └─BertEncoder: 2-2                  --\n",
       "|    |    └─ModuleList: 3-6              85,054,464\n",
       "|    └─BertPooler: 2-3                   --\n",
       "|    |    └─Linear: 3-7                  590,592\n",
       "|    |    └─Tanh: 3-8                    --\n",
       "├─Dropout: 1-2                           --\n",
       "├─Sequential: 1-3                        --\n",
       "|    └─Linear: 2-4                       3,845\n",
       "|    └─Softmax: 2-5                      --\n",
       "=================================================================\n",
       "Total params: 167,360,261\n",
       "Trainable params: 167,360,261\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SexismClassifier()\n",
    "model.load_state_dict(torch.load('models/sexism-classifier-task2.pt'))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-vintage",
   "metadata": {},
   "source": [
    "## Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "still-craft",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_case</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>language</th>\n",
       "      <th>text</th>\n",
       "      <th>task1</th>\n",
       "      <th>task2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>6980</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>lol ! \" this behavior of not letting men tell ...</td>\n",
       "      <td>sexist</td>\n",
       "      <td>ideological-inequality</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>6981</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>rights ? i mean yeah most women especially the...</td>\n",
       "      <td>sexist</td>\n",
       "      <td>ideological-inequality</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>6985</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>stop regarding women as animals who forget tht...</td>\n",
       "      <td>sexist</td>\n",
       "      <td>ideological-inequality</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>6986</td>\n",
       "      <td>gab</td>\n",
       "      <td>en</td>\n",
       "      <td>yeah , it is rough , but not for women . marri...</td>\n",
       "      <td>sexist</td>\n",
       "      <td>objectification</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>6989</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>you were publicly harassing a girl by constant...</td>\n",
       "      <td>sexist</td>\n",
       "      <td>misogyny-non-sexual-violence</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test_case    id   source language  \\\n",
       "2   EXIST2021  6980  twitter       en   \n",
       "3   EXIST2021  6981  twitter       en   \n",
       "7   EXIST2021  6985  twitter       en   \n",
       "8   EXIST2021  6986      gab       en   \n",
       "11  EXIST2021  6989  twitter       en   \n",
       "\n",
       "                                                 text   task1  \\\n",
       "2   lol ! \" this behavior of not letting men tell ...  sexist   \n",
       "3   rights ? i mean yeah most women especially the...  sexist   \n",
       "7   stop regarding women as animals who forget tht...  sexist   \n",
       "8   yeah , it is rough , but not for women . marri...  sexist   \n",
       "11  you were publicly harassing a girl by constant...  sexist   \n",
       "\n",
       "                           task2  label  \n",
       "2         ideological-inequality      0  \n",
       "3         ideological-inequality      0  \n",
       "7         ideological-inequality      0  \n",
       "8                objectification      2  \n",
       "11  misogyny-non-sexual-violence      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('../../Data/EXIST2021_test.tsv', sep='\\t')\n",
    "test_df = test_df[test_df['task1'] == 'sexist']\n",
    "\n",
    "# Un simple pre-procesamiento\n",
    "test_df['text'] = test_df['text'].apply(lambda text: preprocessing.preprocess(text))\n",
    "\n",
    "# Codificamos las etiquetas\n",
    "labels_dict = {'ideological-inequality': 0, 'misogyny-non-sexual-violence': 1,\n",
    "               'objectification': 2, 'sexual-violence': 3, 'stereotyping-dominance': 4}\n",
    "\n",
    "test_df['label'] = test_df['task2'].apply(lambda x: labels_dict[x])\n",
    "\n",
    "test_df_en = test_df[test_df['language'] == 'en']\n",
    "test_df_es = test_df[test_df['language'] == 'es']\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "complex-butler",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 2281\n",
      "Test en: 1158\n",
      "Test es: 1123\n"
     ]
    }
   ],
   "source": [
    "ds_text_test = DataSetText(test_df)\n",
    "ds_text_test_en = DataSetText(test_df_en)\n",
    "ds_text_test_es = DataSetText(test_df_es)\n",
    "\n",
    "print(f'Test: {len(ds_text_test)}')\n",
    "print(f'Test en: {len(ds_text_test_en)}')\n",
    "print(f'Test es: {len(ds_text_test_es)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "indonesian-heater",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "\n",
    "test_dl = DataLoader(\n",
    "    ds_text_test,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4)\n",
    "\n",
    "test_en_dl = DataLoader(\n",
    "    ds_text_test_en,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4)\n",
    "\n",
    "test_es_dl = DataLoader(\n",
    "    ds_text_test_es,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-bidding",
   "metadata": {},
   "source": [
    "## Rendimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "unusual-reduction",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 286/286 [00:10<00:00, 26.32it/s]\n",
      "  0%|          | 0/145 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.5 s, sys: 239 ms, total: 10.8 s\n",
      "Wall time: 10.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 145/145 [00:05<00:00, 25.94it/s]\n",
      "  0%|          | 0/141 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.31 s, sys: 203 ms, total: 5.52 s\n",
      "Wall time: 5.59 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:05<00:00, 25.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.2 s, sys: 199 ms, total: 5.4 s\n",
      "Wall time: 5.46 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%time y_test, y_pred = infer(model, test_dl)\n",
    "%time y_test_en, y_pred_en = infer(model, test_en_dl)\n",
    "%time y_test_es, y_pred_es = infer(model, test_es_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monetary-kitty",
   "metadata": {},
   "source": [
    "En general se tiene que:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "instrumental-charm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "      ideological-inequality       0.68      0.80      0.74       621\n",
      "misogyny-non-sexual-violence       0.61      0.49      0.54       472\n",
      "             objectification       0.60      0.52      0.56       324\n",
      "             sexual-violence       0.76      0.61      0.68       400\n",
      "      stereotyping-dominance       0.54      0.68      0.60       464\n",
      "\n",
      "                    accuracy                           0.64      2281\n",
      "                   macro avg       0.64      0.62      0.62      2281\n",
      "                weighted avg       0.64      0.64      0.63      2281\n",
      "\n",
      "Accuracy: 63.7001\n",
      "F1 score: 62.3797\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=['ideological-inequality', 'misogyny-non-sexual-violence', \n",
    "                                                          'objectification', 'sexual-violence', 'stereotyping-dominance']))\n",
    "\n",
    "print(f'Accuracy: {round(100*accuracy_score(y_test, y_pred), 4)}')\n",
    "print(f'F1 score: {round(100*f1_score(y_test, y_pred, average=\"macro\"), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-prevention",
   "metadata": {},
   "source": [
    "En inglés se tiene que:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "veterinary-victorian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "      ideological-inequality       0.69      0.75      0.72       333\n",
      "misogyny-non-sexual-violence       0.59      0.47      0.52       215\n",
      "             objectification       0.60      0.51      0.55       150\n",
      "             sexual-violence       0.68      0.66      0.67       198\n",
      "      stereotyping-dominance       0.58      0.68      0.62       262\n",
      "\n",
      "                    accuracy                           0.63      1158\n",
      "                   macro avg       0.63      0.61      0.62      1158\n",
      "                weighted avg       0.63      0.63      0.63      1158\n",
      "\n",
      "Accuracy: 63.4715\n",
      "F1 score: 61.6744\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_en, y_pred_en, target_names=['ideological-inequality', 'misogyny-non-sexual-violence', \n",
    "                                                          'objectification', 'sexual-violence', 'stereotyping-dominance']))\n",
    "\n",
    "print(f'Accuracy: {round(100*accuracy_score(y_test_en, y_pred_en), 4)}')\n",
    "print(f'F1 score: {round(100*f1_score(y_test_en, y_pred_en, average=\"macro\"), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-sight",
   "metadata": {},
   "source": [
    "En español se tiene que:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "detailed-honey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "      ideological-inequality       0.67      0.84      0.75       288\n",
      "misogyny-non-sexual-violence       0.62      0.51      0.56       257\n",
      "             objectification       0.61      0.53      0.56       174\n",
      "             sexual-violence       0.89      0.56      0.69       202\n",
      "      stereotyping-dominance       0.51      0.68      0.58       202\n",
      "\n",
      "                    accuracy                           0.64      1123\n",
      "                   macro avg       0.66      0.63      0.63      1123\n",
      "                weighted avg       0.66      0.64      0.64      1123\n",
      "\n",
      "Accuracy: 63.9359\n",
      "F1 score: 62.9523\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_es, y_pred_es, target_names=['ideological-inequality', 'misogyny-non-sexual-violence', \n",
    "                                                          'objectification', 'sexual-violence', 'stereotyping-dominance']))\n",
    "\n",
    "print(f'Accuracy: {round(100*accuracy_score(y_test_es, y_pred_es), 4)}')\n",
    "print(f'F1 score: {round(100*f1_score(y_test_es, y_pred_es, average=\"macro\"), 4)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
