{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "amino-response",
   "metadata": {},
   "source": [
    "# Modelos básicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "royal-desktop",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import spacy\n",
    "from utils import preprocessing\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "from torchtext.data import Field\n",
    "from torchtext.vocab import GloVe, Vectors\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-mambo",
   "metadata": {},
   "source": [
    "Ver [Trained Models & Pipelines](https://spacy.io/models) para los modelos de SpaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "satisfactory-institution",
   "metadata": {},
   "outputs": [],
   "source": [
    "en = spacy.load('en_core_web_md')\n",
    "\n",
    "def tokenize_en(sentence):\n",
    "    return [tok.text for tok in en.tokenizer(sentence)]\n",
    "\n",
    "es = spacy.load('es_core_news_md')\n",
    "\n",
    "def tokenize_es(sentence):\n",
    "    return [tok.text for tok in es.tokenizer(sentence)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "requested-society",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.vocab.GloVe at 0x7f1ffc555160>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descargamos los embeddings\n",
    "GloVe(name='twitter.27B', dim=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supposed-consultancy",
   "metadata": {},
   "source": [
    "## Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "historical-absence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_case</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>language</th>\n",
       "      <th>text</th>\n",
       "      <th>task1</th>\n",
       "      <th>task2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>1</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>she calls herself \" anti-feminazi \" how about ...</td>\n",
       "      <td>sexist</td>\n",
       "      <td>ideological-inequality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>2</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>now , back to these women , the brave and the ...</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>3</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>wow , your skirt is very short . what is it's ...</td>\n",
       "      <td>sexist</td>\n",
       "      <td>objectification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>4</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>incredible ! beautiful ! but i laughed so much...</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>5</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>i find it extremely hard to believe that kelly...</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_case  id   source language  \\\n",
       "0  EXIST2021   1  twitter       en   \n",
       "1  EXIST2021   2  twitter       en   \n",
       "2  EXIST2021   3  twitter       en   \n",
       "3  EXIST2021   4  twitter       en   \n",
       "4  EXIST2021   5  twitter       en   \n",
       "\n",
       "                                                text       task1  \\\n",
       "0  she calls herself \" anti-feminazi \" how about ...      sexist   \n",
       "1  now , back to these women , the brave and the ...  non-sexist   \n",
       "2  wow , your skirt is very short . what is it's ...      sexist   \n",
       "3  incredible ! beautiful ! but i laughed so much...  non-sexist   \n",
       "4  i find it extremely hard to believe that kelly...  non-sexist   \n",
       "\n",
       "                    task2  \n",
       "0  ideological-inequality  \n",
       "1              non-sexist  \n",
       "2         objectification  \n",
       "3              non-sexist  \n",
       "4              non-sexist  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../../Data/EXIST2021_training.tsv', sep='\\t')\n",
    "# train = pd.read_csv('../../Data/EXIST2021_training_spell_checked.csv', sep=',')\n",
    "\n",
    "# Un simple pre-procesamiento\n",
    "train['text'] = train['text'].apply(lambda text: preprocessing.preprocess(text))\n",
    "\n",
    "train_en = train[train['language'] == 'en']\n",
    "train_es = train[train['language'] == 'es']\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "swiss-bahamas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_case</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>language</th>\n",
       "      <th>text</th>\n",
       "      <th>task1</th>\n",
       "      <th>task2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>6978</td>\n",
       "      <td>gab</td>\n",
       "      <td>en</td>\n",
       "      <td>pennsylvania state rep horrifies with opening ...</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>6979</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>he sounds like as ass , and very condescending .</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>6980</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>lol ! \" this behavior of not letting men tell ...</td>\n",
       "      <td>sexist</td>\n",
       "      <td>ideological-inequality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>6981</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>rights ? i mean yeah most women especially the...</td>\n",
       "      <td>sexist</td>\n",
       "      <td>ideological-inequality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>6982</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>the jack manifold appreciation i ’ m seeing is...</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>non-sexist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_case    id   source language  \\\n",
       "0  EXIST2021  6978      gab       en   \n",
       "1  EXIST2021  6979  twitter       en   \n",
       "2  EXIST2021  6980  twitter       en   \n",
       "3  EXIST2021  6981  twitter       en   \n",
       "4  EXIST2021  6982  twitter       en   \n",
       "\n",
       "                                                text       task1  \\\n",
       "0  pennsylvania state rep horrifies with opening ...  non-sexist   \n",
       "1   he sounds like as ass , and very condescending .  non-sexist   \n",
       "2  lol ! \" this behavior of not letting men tell ...      sexist   \n",
       "3  rights ? i mean yeah most women especially the...      sexist   \n",
       "4  the jack manifold appreciation i ’ m seeing is...  non-sexist   \n",
       "\n",
       "                    task2  \n",
       "0              non-sexist  \n",
       "1              non-sexist  \n",
       "2  ideological-inequality  \n",
       "3  ideological-inequality  \n",
       "4              non-sexist  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('../../Data/EXIST2021_test.tsv', sep='\\t')\n",
    "# test = pd.read_csv('../../Data/EXIST2021_test_spell_checked.csv', sep=',')\n",
    "\n",
    "# Un simple pre-procesamiento\n",
    "test['text'] = test['text'].apply(lambda text: preprocessing.preprocess(text))\n",
    "\n",
    "test_en = test[test['language'] == 'en']\n",
    "test_es = test[test['language'] == 'es']\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "nominated-baking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['non-sexist', 'sexist'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(train['task1'])\n",
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "understanding-frank",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'incredible ! aaa :D beautiful ! but i laughed sooo much when i read about you drifting in your wheelchair . i can just picture it lol'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '@AurelieGuiboud Incredible! AAAA :D Beautiful!But I laughed sooooooo much when I read about you drifting in your wheelchair.I can just picture it  https://t.co/uvl5HhbmbR lol'\n",
    "preprocessing.preprocess(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-laser",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-inclusion",
   "metadata": {},
   "source": [
    "### Baseline (tf-idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-calvin",
   "metadata": {},
   "source": [
    "#### English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ranging-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el vectorizer\n",
    "vectorizer_en = TfidfVectorizer(analyzer='word', stop_words=None, lowercase=True)\n",
    "vectorizer_en.fit(train_en['text'])\n",
    "\n",
    "# Transformamos\n",
    "X_train_en = vectorizer_en.transform(train_en['text'])\n",
    "X_test_en = vectorizer_en.transform(test_en['text'])\n",
    "\n",
    "y_train_en = label_encoder.transform(train_en['task1'])\n",
    "y_test_en = label_encoder.transform(test_en['task1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "proud-quantity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 483 ms, sys: 1.59 s, total: 2.07 s\n",
      "Wall time: 147 ms\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.67      0.76      0.71      1050\n",
      "      sexist       0.75      0.66      0.70      1158\n",
      "\n",
      "    accuracy                           0.71      2208\n",
      "   macro avg       0.71      0.71      0.71      2208\n",
      "weighted avg       0.71      0.71      0.71      2208\n",
      "\n",
      "Accuracy: 0.707\n"
     ]
    }
   ],
   "source": [
    "clf_en = LogisticRegression(max_iter=1000)\n",
    "%time clf_en.fit(X_train_en, y_train_en)\n",
    "\n",
    "y_pred_en = clf_en.predict(X_test_en)\n",
    "\n",
    "print(classification_report(y_test_en, y_pred_en, target_names=['non-sexist', 'sexist']))\n",
    "print(f'Accuracy: {round(accuracy_score(y_test_en, y_pred_en), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-development",
   "metadata": {},
   "source": [
    "#### Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "accurate-blink",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el vectorizer\n",
    "vectorizer_es = TfidfVectorizer(analyzer='word', stop_words=None, lowercase=True)\n",
    "vectorizer_es.fit(train_es['text'])\n",
    "\n",
    "# Transformamos\n",
    "X_train_es = vectorizer_es.transform(train_es['text'])\n",
    "X_test_es = vectorizer_es.transform(test_es['text'])\n",
    "\n",
    "y_train_es = label_encoder.transform(train_es['task1'])\n",
    "y_test_es = label_encoder.transform(test_es['task1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "certified-density",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 222 ms, sys: 498 ms, total: 720 ms\n",
      "Wall time: 53.1 ms\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.65      0.81      0.72      1037\n",
      "      sexist       0.77      0.60      0.67      1123\n",
      "\n",
      "    accuracy                           0.70      2160\n",
      "   macro avg       0.71      0.70      0.70      2160\n",
      "weighted avg       0.71      0.70      0.70      2160\n",
      "\n",
      "Accuracy: 0.6981\n"
     ]
    }
   ],
   "source": [
    "clf_es = LogisticRegression(max_iter=1000)\n",
    "%time clf_es.fit(X_train_es, y_train_es)\n",
    "\n",
    "y_pred_es = clf_es.predict(X_test_es)\n",
    "\n",
    "print(classification_report(y_test_es, y_pred_es, target_names=['non-sexist', 'sexist']))\n",
    "print(f'Accuracy: {round(accuracy_score(y_test_es, y_pred_es), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-booking",
   "metadata": {},
   "source": [
    "#### Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "objective-breakfast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.66      0.78      0.72      2087\n",
      "      sexist       0.76      0.63      0.69      2281\n",
      "\n",
      "    accuracy                           0.70      4368\n",
      "   macro avg       0.71      0.71      0.70      4368\n",
      "weighted avg       0.71      0.70      0.70      4368\n",
      "\n",
      "Accuracy: 0.7026\n"
     ]
    }
   ],
   "source": [
    "y_test = np.hstack((y_test_en, y_test_es))\n",
    "y_pred = np.hstack((y_pred_en, y_pred_es))\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=['non-sexist', 'sexist']))\n",
    "print(f'Accuracy: {round(accuracy_score(y_test, y_pred), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-israeli",
   "metadata": {},
   "source": [
    "### Promedio de vectores de palabras con GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-store",
   "metadata": {},
   "source": [
    "Para los embeddings en inglés usaré los que están pre-entrenados con el corpus de Twitter, pues los datos de esta tarea también son de Twitter.\n",
    "\n",
    "Debido a que Torchtext sólo tiene por defecto embeddings en inglés hay que hacer otras cosas para cargar los que están en español. Primero, hay que descargarlos de [GloVe Spanish](http://dcc.uchile.cl/~jperez/word-embeddings/glove-sbwc.i25.vec.gz) y ponerlos en la carpeta `.vector_cache` del directorio actual. Para ver otros embeddings pre-entrenados en español ver [spanish-word-embeddings](https://github.com/dccuchile/spanish-word-embeddings).\n",
    "\n",
    "Ver lo siguiente para algunos detalles de cómo cargarlos para la capa de embeddings:\n",
    "\n",
    "- [Use pretrained embedding in Spanish with Torchtext](https://stackoverflow.com/questions/52224555/use-pretrained-embedding-in-spanish-with-torchtext)\n",
    "- [Handling German Text with torchtext](https://www.innoq.com/en/blog/handling-german-text-with-torchtext/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "emotional-cooling",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://dcc.uchile.cl/~jperez/word-embeddings/glove-sbwc.i25.vec.gz -P .vector_cache\n",
    "!gunzip .vector_cache/glove-sbwc.i25.vec.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "statistical-logging",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_vector(text, text_field, vocab):\n",
    "    \"\"\"\n",
    "    Promedia los vectores de palabras de un texto.\n",
    "    \"\"\"\n",
    "    vectors = np.array([vocab.vectors[vocab[token]].numpy() for token in text_field.preprocess(text)])\n",
    "    return np.mean(vectors, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-placement",
   "metadata": {},
   "source": [
    "#### English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "selected-tourism",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 3855),\n",
       " ('the', 2737),\n",
       " ('to', 2508),\n",
       " (',', 2506),\n",
       " ('a', 2432),\n",
       " ('i', 2243),\n",
       " ('and', 2023),\n",
       " ('#', 2000),\n",
       " ('you', 1961),\n",
       " ('’', 1531)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definimos cómo se preprocesará el texto\n",
    "text_field_en = Field(tokenize=tokenize_en, lower=True)\n",
    "\n",
    "# Preprocesamos el texto\n",
    "preprocessed_train_text_en = train_en['text'].apply(lambda x: text_field_en.preprocess(x))\n",
    "preprocessed_test_text_en = test_en['text'].apply(lambda x: text_field_en.preprocess(x))\n",
    "\n",
    "# Contruimos el vocabulario\n",
    "text_field_en.build_vocab(preprocessed_train_text_en, vectors='glove.twitter.27B.200d', vectors_cache='.vector_cache')\n",
    "vocab_en = text_field_en.vocab\n",
    "vocab_en.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "decreased-synthetic",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3436/3436 [00:00<00:00, 6374.65it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_en = np.zeros(shape=(train_en.shape[0], 200))\n",
    "\n",
    "for i, text in tqdm(enumerate(train_en['text']), total=train_en.shape[0]):\n",
    "    X_train_en[i, :] = mean_vector(text, text_field_en, vocab_en)\n",
    "    \n",
    "y_train_en = label_encoder.transform(train_en['task1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "promotional-kitchen",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2208/2208 [00:00<00:00, 6178.45it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test_en = np.zeros(shape=(test_en.shape[0], 200))\n",
    "\n",
    "for i, text in tqdm(enumerate(test_en['text']), total=test_en.shape[0]):\n",
    "    X_test_en[i, :] = mean_vector(text, text_field_en, vocab_en)\n",
    "    \n",
    "y_test_en = label_encoder.transform(test_en['task1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "clean-villa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 432 ms, sys: 717 ms, total: 1.15 s\n",
      "Wall time: 119 ms\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.62      0.75      0.68      1050\n",
      "      sexist       0.72      0.58      0.64      1158\n",
      "\n",
      "    accuracy                           0.66      2208\n",
      "   macro avg       0.67      0.67      0.66      2208\n",
      "weighted avg       0.67      0.66      0.66      2208\n",
      "\n",
      "Accuracy: 0.6635\n"
     ]
    }
   ],
   "source": [
    "clf_en = LogisticRegression(max_iter=1000)\n",
    "%time clf_en.fit(X_train_en, y_train_en)\n",
    "\n",
    "y_pred_en = clf_en.predict(X_test_en)\n",
    "\n",
    "print(classification_report(y_test_en, y_pred_en, target_names=['non-sexist', 'sexist']))\n",
    "print(f'Accuracy: {round(accuracy_score(y_test_en, y_pred_en), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-scene",
   "metadata": {},
   "source": [
    "#### Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "successful-commodity",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_es = Vectors('glove-sbwc.i25.vec', cache='.vector_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "indian-remains",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 4459),\n",
       " ('que', 4001),\n",
       " ('de', 3808),\n",
       " ('.', 3031),\n",
       " ('la', 2788),\n",
       " ('y', 2674),\n",
       " ('a', 2564),\n",
       " ('no', 2150),\n",
       " ('el', 1956),\n",
       " ('en', 1576)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definimos cómo se preprocesará el texto\n",
    "text_field_es = Field(tokenize=tokenize_es, lower=True)\n",
    "\n",
    "# Preprocesamos el texto\n",
    "preprocessed_train_text_es = train_es['text'].apply(lambda x: text_field_es.preprocess(x))\n",
    "preprocessed_test_text_es = test_es['text'].apply(lambda x: text_field_es.preprocess(x))\n",
    "\n",
    "# Contruimos el vocabulario\n",
    "text_field_es.build_vocab(preprocessed_train_text_es, vectors=vectors_es)\n",
    "vocab_es = text_field_es.vocab\n",
    "vocab_es.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "turned-jonathan",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3541/3541 [00:00<00:00, 7379.75it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_es = np.zeros(shape=(train_es.shape[0], 300))\n",
    "\n",
    "for i, text in tqdm(enumerate(train_es['text']), total=train_es.shape[0]):\n",
    "    X_train_es[i, :] = mean_vector(text, text_field_es, vocab_es)\n",
    "    \n",
    "y_train_es = label_encoder.transform(train_es['task1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "threaded-swift",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3541/3541 [00:00<00:00, 7362.50it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_es = np.zeros(shape=(train_es.shape[0], 300))\n",
    "\n",
    "for i, text in tqdm(enumerate(train_es['text']), total=train_es.shape[0]):\n",
    "    X_train_es[i, :] = mean_vector(text, text_field_es, vocab_es)\n",
    "    \n",
    "y_train_es = label_encoder.transform(train_es['task1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "suspended-deficit",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2160/2160 [00:00<00:00, 7125.05it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test_es = np.zeros(shape=(test_es.shape[0], 300))\n",
    "\n",
    "for i, text in tqdm(enumerate(test_es['text']), total=test_es.shape[0]):\n",
    "    X_test_es[i, :] = mean_vector(text, text_field_es, vocab_es)\n",
    "    \n",
    "y_test_es = label_encoder.transform(test_es['task1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "endless-worry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 576 ms, sys: 1.16 s, total: 1.74 s\n",
      "Wall time: 113 ms\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.79      0.70      1037\n",
      "           1       0.75      0.58      0.65      1123\n",
      "\n",
      "    accuracy                           0.68      2160\n",
      "   macro avg       0.69      0.68      0.68      2160\n",
      "weighted avg       0.69      0.68      0.68      2160\n",
      "\n",
      "Accuracy: 0.6782\n"
     ]
    }
   ],
   "source": [
    "clf_es = LogisticRegression(max_iter=1000)\n",
    "%time clf_es.fit(X_train_es, y_train_es)\n",
    "\n",
    "y_pred_es = clf_es.predict(X_test_es)\n",
    "\n",
    "print(classification_report(y_test_es, y_pred_es))\n",
    "print(f'Accuracy: {round(accuracy_score(y_test_es, y_pred_es), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-malaysia",
   "metadata": {},
   "source": [
    "#### Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "killing-tribune",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.63      0.77      0.69      2087\n",
      "      sexist       0.73      0.58      0.65      2281\n",
      "\n",
      "    accuracy                           0.67      4368\n",
      "   macro avg       0.68      0.68      0.67      4368\n",
      "weighted avg       0.68      0.67      0.67      4368\n",
      "\n",
      "Accuracy: 0.6708\n"
     ]
    }
   ],
   "source": [
    "y_test = np.hstack((y_test_en, y_test_es))\n",
    "y_pred = np.hstack((y_pred_en, y_pred_es))\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=['non-sexist', 'sexist']))\n",
    "print(f'Accuracy: {round(accuracy_score(y_test, y_pred), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transparent-quarter",
   "metadata": {},
   "source": [
    "### Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-commons",
   "metadata": {},
   "source": [
    "#### English"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-playing",
   "metadata": {},
   "source": [
    "Al igual que los vectores usados en GloVe haré que los embeddings the Doc2Vec tengan dimesión igual a 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "active-niger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.1 s, sys: 1.99 s, total: 22.1 s\n",
      "Wall time: 11.8 s\n"
     ]
    }
   ],
   "source": [
    "documents_en = [TaggedDocument(doc, [i]) for doc, i in zip(preprocessed_train_text_en, train_en['task1'])]\n",
    "%time doc2vec_en = Doc2Vec(documents_en, vector_size=200, window=5, min_count=1, workers=4, seed=42, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "scheduled-briefing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3436/3436 [00:07<00:00, 431.90it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_en = np.zeros(shape=(train_en.shape[0], 200))\n",
    "\n",
    "for i, text in tqdm(enumerate(train_en['text']), total=train_en.shape[0]):\n",
    "    X_train_en[i, :] = doc2vec_en.infer_vector(text_field_en.preprocess(text))\n",
    "    \n",
    "y_train_en = label_encoder.transform(train_en['task1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "hollow-startup",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2208/2208 [00:05<00:00, 426.89it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test_en = np.zeros(shape=(test_en.shape[0], 200))\n",
    "\n",
    "for i, text in tqdm(enumerate(test_en['text']), total=test_en.shape[0]):\n",
    "    X_test_en[i, :] = doc2vec_en.infer_vector(text_field_en.preprocess(text))\n",
    "    \n",
    "y_test_en = label_encoder.transform(test_en['task1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "considered-attention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 176 ms, sys: 454 ms, total: 630 ms\n",
      "Wall time: 45.4 ms\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.62      0.59      1050\n",
      "           1       0.62      0.56      0.59      1158\n",
      "\n",
      "    accuracy                           0.59      2208\n",
      "   macro avg       0.59      0.59      0.59      2208\n",
      "weighted avg       0.59      0.59      0.59      2208\n",
      "\n",
      "Accuracy: 0.5856\n"
     ]
    }
   ],
   "source": [
    "clf_en = LogisticRegression(max_iter=1000)\n",
    "%time clf_en.fit(X_train_en, y_train_en)\n",
    "\n",
    "y_pred_en = clf_en.predict(X_test_en)\n",
    "\n",
    "print(classification_report(y_test_en, y_pred_en))\n",
    "print(f'Accuracy: {round(accuracy_score(y_test_en, y_pred_en), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-expansion",
   "metadata": {},
   "source": [
    "#### Spanish\n",
    "Al igual que los vectores usados en GloVe haré que los embeddings the Doc2Vec tengan dimesión igual a 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "acute-stability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.2 s, sys: 1.88 s, total: 24.1 s\n",
      "Wall time: 12 s\n"
     ]
    }
   ],
   "source": [
    "documents_es = [TaggedDocument(doc, [i]) for doc, i in zip(preprocessed_train_text_es, train_es['task1'])]\n",
    "%time doc2vec_es = Doc2Vec(documents_es, vector_size=300, window=5, min_count=1, workers=4, seed=42, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "brief-action",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3541/3541 [00:09<00:00, 391.26it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_es = np.zeros(shape=(train_es.shape[0], 300))\n",
    "\n",
    "for i, text in tqdm(enumerate(train_es['text']), total=train_es.shape[0]):\n",
    "    X_train_es[i, :] = doc2vec_es.infer_vector(text_field_es.preprocess(text))\n",
    "    \n",
    "y_train_es = label_encoder.transform(train_es['task1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "passive-nirvana",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2160/2160 [00:05<00:00, 416.57it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test_es = np.zeros(shape=(test_es.shape[0], 300))\n",
    "\n",
    "for i, text in tqdm(enumerate(test_es['text']), total=test_es.shape[0]):\n",
    "    X_test_es[i, :] = doc2vec_es.infer_vector(text_field_es.preprocess(text))\n",
    "    \n",
    "y_test_es = label_encoder.transform(test_es['task1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "subjective-knight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 316 ms, sys: 720 ms, total: 1.04 s\n",
      "Wall time: 77.4 ms\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.61      0.59      1037\n",
      "           1       0.62      0.60      0.61      1123\n",
      "\n",
      "    accuracy                           0.60      2160\n",
      "   macro avg       0.60      0.60      0.60      2160\n",
      "weighted avg       0.60      0.60      0.60      2160\n",
      "\n",
      "Accuracy: 0.6009\n"
     ]
    }
   ],
   "source": [
    "clf_es = LogisticRegression(max_iter=1000)\n",
    "%time clf_es.fit(X_train_es, y_train_es)\n",
    "\n",
    "y_pred_es = clf_es.predict(X_test_es)\n",
    "\n",
    "print(classification_report(y_test_es, y_pred_es))\n",
    "print(f'Accuracy: {round(accuracy_score(y_test_es, y_pred_es), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-guarantee",
   "metadata": {},
   "source": [
    "#### Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "natural-montreal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.57      0.61      0.59      2087\n",
      "      sexist       0.62      0.58      0.60      2281\n",
      "\n",
      "    accuracy                           0.59      4368\n",
      "   macro avg       0.59      0.59      0.59      4368\n",
      "weighted avg       0.59      0.59      0.59      4368\n",
      "\n",
      "Accuracy: 0.5932\n"
     ]
    }
   ],
   "source": [
    "y_test = np.hstack((y_test_en, y_test_es))\n",
    "y_pred = np.hstack((y_pred_en, y_pred_es))\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=['non-sexist', 'sexist']))\n",
    "print(f'Accuracy: {round(accuracy_score(y_test, y_pred), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-float",
   "metadata": {},
   "source": [
    "### sentence-BERT\n",
    "\n",
    "En [Pretrained Models](https://www.sbert.net/docs/pretrained_models.html) están todos los modelos preentrenados que hay. Los modelos fuertes en una tarea, serán débiles para otra tarea, por lo tanto, es importante seleccionar el modelo adecuado para cada tarea. Como no hay ninguno en específico para la tarea de análisis de sentimientos usaré **paraphrase-distilroberta-base-v1**, el cual recomiendan para varias aplicaciones.\n",
    "\n",
    "**distiluse-base-multilingual-cased-v1:** Multilingual knowledge distilled version of multilingual Universal Sentence Encoder. Supports 15 languages: Arabic, Chinese, Dutch, English, French, German, Italian, Korean, Polish, Portuguese, Russian, Spanish, Turkish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "entertaining-peninsula",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descagamos el modelo\n",
    "model = SentenceTransformer('distiluse-base-multilingual-cased-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respiratory-raise",
   "metadata": {},
   "source": [
    "#### English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "lyric-abraham",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train_en = [' '.join(review) for review in preprocessed_train_text_en]\n",
    "sentences_test_en = [' '.join(review) for review in preprocessed_test_text_en]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "freelance-lucas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cab6e1c6891c4543a7e4d48bf3c5ca43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.7 s, sys: 704 ms, total: 6.4 s\n",
      "Wall time: 5.26 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25c21d953ee42dc949464a9f017c242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.9 s, sys: 147 ms, total: 3.04 s\n",
      "Wall time: 2.26 s\n"
     ]
    }
   ],
   "source": [
    "# Cada embedding tiene dimensión igual a 768\n",
    "%time X_train_en = model.encode(sentences_train_en, show_progress_bar=True)\n",
    "%time X_test_en = model.encode(sentences_test_en, show_progress_bar=True)\n",
    "\n",
    "y_train_en = label_encoder.transform(train_en['task1'])\n",
    "y_test_en = label_encoder.transform(test_en['task1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "reliable-wagner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 347 ms, sys: 303 ms, total: 650 ms\n",
      "Wall time: 51.6 ms\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73      1050\n",
      "           1       0.76      0.73      0.74      1158\n",
      "\n",
      "    accuracy                           0.74      2208\n",
      "   macro avg       0.74      0.74      0.74      2208\n",
      "weighted avg       0.74      0.74      0.74      2208\n",
      "\n",
      "Accuracy: 0.7373\n"
     ]
    }
   ],
   "source": [
    "clf_en = LogisticRegression(max_iter=1000)\n",
    "%time clf_en.fit(X_train_en, y_train_en)\n",
    "\n",
    "y_pred_en = clf_en.predict(X_test_en)\n",
    "\n",
    "print(classification_report(y_test_en, y_pred_en))\n",
    "print(f'Accuracy: {round(accuracy_score(y_test_en, y_pred_en), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-southeast",
   "metadata": {},
   "source": [
    "#### Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "global-nowhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train_es = [' '.join(review) for review in preprocessed_train_text_es]\n",
    "sentences_test_es = [' '.join(review) for review in preprocessed_test_text_es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "figured-constitutional",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d8678d3405b499893bf9c61377fadce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/111 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.59 s, sys: 213 ms, total: 4.8 s\n",
      "Wall time: 3.59 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa9321f7274404d86576c6d6e3d1de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.75 s, sys: 190 ms, total: 2.94 s\n",
      "Wall time: 2.19 s\n"
     ]
    }
   ],
   "source": [
    "# Cada embedding tiene dimensión igual a 768\n",
    "%time X_train_es = model.encode(sentences_train_es, show_progress_bar=True)\n",
    "%time X_test_es = model.encode(sentences_test_es, show_progress_bar=True)\n",
    "\n",
    "y_train_es = label_encoder.transform(train_es['task1'])\n",
    "y_test_es = label_encoder.transform(test_es['task1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "simple-format",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 261 ms, sys: 382 ms, total: 644 ms\n",
      "Wall time: 48.3 ms\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.80      0.74      1037\n",
      "           1       0.78      0.66      0.72      1123\n",
      "\n",
      "    accuracy                           0.73      2160\n",
      "   macro avg       0.73      0.73      0.73      2160\n",
      "weighted avg       0.73      0.73      0.73      2160\n",
      "\n",
      "Accuracy: 0.7264\n"
     ]
    }
   ],
   "source": [
    "clf_es = LogisticRegression(max_iter=1000)\n",
    "%time clf_es.fit(X_train_es, y_train_es)\n",
    "\n",
    "y_pred_es = clf_es.predict(X_test_es)\n",
    "\n",
    "print(classification_report(y_test_es, y_pred_es))\n",
    "print(f'Accuracy: {round(accuracy_score(y_test_es, y_pred_es), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-refrigerator",
   "metadata": {},
   "source": [
    "#### Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "known-reminder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.70      0.77      0.73      2087\n",
      "      sexist       0.77      0.69      0.73      2281\n",
      "\n",
      "    accuracy                           0.73      4368\n",
      "   macro avg       0.73      0.73      0.73      4368\n",
      "weighted avg       0.74      0.73      0.73      4368\n",
      "\n",
      "Accuracy: 0.7319\n"
     ]
    }
   ],
   "source": [
    "y_test = np.hstack((y_test_en, y_test_es))\n",
    "y_pred = np.hstack((y_pred_en, y_pred_es))\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=['non-sexist', 'sexist']))\n",
    "print(f'Accuracy: {round(accuracy_score(y_test, y_pred), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "similar-chapter",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "\n",
    "De los distintos modelos el mejor parece ser el de BERT que ha sido entrenado con varios idiomas.\n",
    "\n",
    "- Al hacer la clasificación sin hacer el spell-check se obtiene:\n",
    "\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}\n",
    ".tg .tg-7btt{border-color:inherit;font-weight:bold;text-align:center;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-7btt\" rowspan=\"2\">Model</th>\n",
    "    <th class=\"tg-7btt\" colspan=\"3\">Task-1 (accuracy)</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-7btt\">English</td>\n",
    "    <td class=\"tg-7btt\">Spanish</td>\n",
    "    <td class=\"tg-7btt\">Total</td>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-c3ow\">tf-idf</td>\n",
    "    <td class=\"tg-c3ow\">70.70</td>\n",
    "    <td class=\"tg-c3ow\">69.81</td>\n",
    "    <td class=\"tg-c3ow\">70.26</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-c3ow\">GloVe</td>\n",
    "    <td class=\"tg-c3ow\">66.35</td>\n",
    "    <td class=\"tg-c3ow\">67.82</td>\n",
    "    <td class=\"tg-c3ow\">67.08</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-c3ow\">Doc2Vec</td>\n",
    "    <td class=\"tg-c3ow\">57.43</td>\n",
    "    <td class=\"tg-c3ow\">59.31</td>\n",
    "    <td class=\"tg-c3ow\">58.36</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-c3ow\">sentence-BERT</td>\n",
    "    <td class=\"tg-c3ow\">73.73</td>\n",
    "    <td class=\"tg-c3ow\">72.64</td>\n",
    "    <td class=\"tg-c3ow\">73.19</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "- Al hacer la clasificación con el spell-check se obtiene:\n",
    "\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}\n",
    ".tg .tg-7btt{border-color:inherit;font-weight:bold;text-align:center;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-7btt\" rowspan=\"2\">Model</th>\n",
    "    <th class=\"tg-7btt\" colspan=\"3\">Task-1 (accuracy)</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-7btt\">English</td>\n",
    "    <td class=\"tg-7btt\">Spanish</td>\n",
    "    <td class=\"tg-7btt\">Total</td>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-c3ow\">tf-idf</td>\n",
    "    <td class=\"tg-c3ow\">70.11</td>\n",
    "    <td class=\"tg-c3ow\">70.60</td>\n",
    "    <td class=\"tg-c3ow\">70.35</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-c3ow\">GloVe</td>\n",
    "    <td class=\"tg-c3ow\">66.85</td>\n",
    "    <td class=\"tg-c3ow\">67.55</td>\n",
    "    <td class=\"tg-c3ow\">67.19</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-c3ow\">Doc2Vec</td>\n",
    "    <td class=\"tg-c3ow\">57.07</td>\n",
    "    <td class=\"tg-c3ow\">58.29</td>\n",
    "    <td class=\"tg-c3ow\">57.67</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-c3ow\">sentence-BERT</td>\n",
    "    <td class=\"tg-c3ow\">73.01</td>\n",
    "    <td class=\"tg-c3ow\">71.20</td>\n",
    "    <td class=\"tg-c3ow\">72.12</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "- En realidad parece empeorar un poco con el spell-check (principalmente en sentence-BERT que es el que mejor sale), además de que es algo tardado hacerlo, por lo que mejor no usaré el spell-check. \n",
    "- Por otro lado, hacer el pre-procesamiento parece ayudar un poco."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
