{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "expected-italic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from torchtext.data import Field\n",
    "from torchtext.vocab import GloVe\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, f1_score\n",
    "\n",
    "import gdown\n",
    "from utils import preprocessing\n",
    "from utils.evaluation import DataSetText, SexismClassifier, infer\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clinical-billion",
   "metadata": {},
   "source": [
    "# Evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-helmet",
   "metadata": {},
   "source": [
    "## Modelos\n",
    "\n",
    "Primero necesitamos descargar los modelos ya entrenados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dynamic-links",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "external-stomach",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://drive.google.com/uc?id=1V0VbdwXDcFP6f0GrdCna1SQqqkZpBOLW'\n",
    "output = 'models/sexism-classifier-task1.pt'\n",
    "\n",
    "gdown.download(url, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rough-latex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "├─BertModel: 1-1                         --\n",
       "|    └─BertEmbeddings: 2-1               --\n",
       "|    |    └─Embedding: 3-1               81,315,072\n",
       "|    |    └─Embedding: 3-2               393,216\n",
       "|    |    └─Embedding: 3-3               1,536\n",
       "|    |    └─LayerNorm: 3-4               1,536\n",
       "|    |    └─Dropout: 3-5                 --\n",
       "|    └─BertEncoder: 2-2                  --\n",
       "|    |    └─ModuleList: 3-6              85,054,464\n",
       "|    └─BertPooler: 2-3                   --\n",
       "|    |    └─Linear: 3-7                  590,592\n",
       "|    |    └─Tanh: 3-8                    --\n",
       "├─Dropout: 1-2                           --\n",
       "├─Sequential: 1-3                        --\n",
       "|    └─Linear: 2-4                       1,538\n",
       "|    └─Softmax: 2-5                      --\n",
       "=================================================================\n",
       "Total params: 167,357,954\n",
       "Trainable params: 167,357,954\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SexismClassifier()\n",
    "model.load_state_dict(torch.load('models/sexism-classifier-task1.pt'))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-swimming",
   "metadata": {},
   "source": [
    "## Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "established-negative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_case</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>language</th>\n",
       "      <th>text</th>\n",
       "      <th>task1</th>\n",
       "      <th>task2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>6978</td>\n",
       "      <td>gab</td>\n",
       "      <td>en</td>\n",
       "      <td>pennsylvania state rep horrifies with opening ...</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>6979</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>he sounds like as ass , and very condescending .</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>6980</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>lol ! \" this behavior of not letting men tell ...</td>\n",
       "      <td>sexist</td>\n",
       "      <td>ideological-inequality</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>6981</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>rights ? i mean yeah most women especially the...</td>\n",
       "      <td>sexist</td>\n",
       "      <td>ideological-inequality</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EXIST2021</td>\n",
       "      <td>6982</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>the jack manifold appreciation i ’ m seeing is...</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_case    id   source language  \\\n",
       "0  EXIST2021  6978      gab       en   \n",
       "1  EXIST2021  6979  twitter       en   \n",
       "2  EXIST2021  6980  twitter       en   \n",
       "3  EXIST2021  6981  twitter       en   \n",
       "4  EXIST2021  6982  twitter       en   \n",
       "\n",
       "                                                text       task1  \\\n",
       "0  pennsylvania state rep horrifies with opening ...  non-sexist   \n",
       "1   he sounds like as ass , and very condescending .  non-sexist   \n",
       "2  lol ! \" this behavior of not letting men tell ...      sexist   \n",
       "3  rights ? i mean yeah most women especially the...      sexist   \n",
       "4  the jack manifold appreciation i ’ m seeing is...  non-sexist   \n",
       "\n",
       "                    task2  label  \n",
       "0              non-sexist      0  \n",
       "1              non-sexist      0  \n",
       "2  ideological-inequality      1  \n",
       "3  ideological-inequality      1  \n",
       "4              non-sexist      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('../../Data/EXIST2021_test.tsv', sep='\\t')\n",
    "\n",
    "# Un simple pre-procesamiento\n",
    "test_df['text'] = test_df['text'].apply(lambda text: preprocessing.preprocess(text))\n",
    "\n",
    "# Codificamos las etiquetas\n",
    "labels_dict = {'non-sexist': 0, 'sexist': 1}\n",
    "\n",
    "test_df['label'] = test_df['task1'].apply(lambda x: labels_dict[x])\n",
    "\n",
    "test_df_en = test_df[test_df['language'] == 'en']\n",
    "test_df_es = test_df[test_df['language'] == 'es']\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "technological-denmark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 4368\n",
      "Test en: 2208\n",
      "Test es: 2160\n"
     ]
    }
   ],
   "source": [
    "ds_text_test = DataSetText(test_df)\n",
    "ds_text_test_en = DataSetText(test_df_en)\n",
    "ds_text_test_es = DataSetText(test_df_es)\n",
    "\n",
    "print(f'Test: {len(ds_text_test)}')\n",
    "print(f'Test en: {len(ds_text_test_en)}')\n",
    "print(f'Test es: {len(ds_text_test_es)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "swedish-graphics",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "\n",
    "test_dl = DataLoader(\n",
    "    ds_text_test,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4)\n",
    "\n",
    "test_en_dl = DataLoader(\n",
    "    ds_text_test_en,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4)\n",
    "\n",
    "test_es_dl = DataLoader(\n",
    "    ds_text_test_es,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lovely-adelaide",
   "metadata": {},
   "source": [
    "## Rendimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "verified-costume",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 546/546 [00:21<00:00, 25.89it/s]\n",
      "  0%|          | 0/276 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.6 s, sys: 320 ms, total: 20.9 s\n",
      "Wall time: 21.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 276/276 [00:10<00:00, 25.62it/s]\n",
      "  0%|          | 0/270 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.4 s, sys: 233 ms, total: 10.7 s\n",
      "Wall time: 10.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 270/270 [00:10<00:00, 25.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.3 s, sys: 237 ms, total: 10.5 s\n",
      "Wall time: 10.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%time y_test, y_pred = infer(model, test_dl)\n",
    "%time y_test_en, y_pred_en = infer(model, test_en_dl)\n",
    "%time y_test_es, y_pred_es = infer(model, test_es_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genetic-grove",
   "metadata": {},
   "source": [
    "En general se tiene que:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "every-barrel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.75      0.73      0.74      2087\n",
      "      sexist       0.76      0.77      0.77      2281\n",
      "\n",
      "    accuracy                           0.75      4368\n",
      "   macro avg       0.75      0.75      0.75      4368\n",
      "weighted avg       0.75      0.75      0.75      4368\n",
      "\n",
      "Accuracy: 75.2747\n",
      "F1 score: 75.1999\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=['non-sexist', 'sexist']))\n",
    "\n",
    "print(f'Accuracy: {round(100*accuracy_score(y_test, y_pred), 4)}')\n",
    "print(f'F1 score: {round(100*f1_score(y_test, y_pred, average=\"macro\"), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-yahoo",
   "metadata": {},
   "source": [
    "En inglés se tiene que:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "specified-elephant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.77      0.68      0.72      1050\n",
      "      sexist       0.74      0.81      0.77      1158\n",
      "\n",
      "    accuracy                           0.75      2208\n",
      "   macro avg       0.75      0.75      0.75      2208\n",
      "weighted avg       0.75      0.75      0.75      2208\n",
      "\n",
      "Accuracy: 74.8641\n",
      "F1 score: 74.5908\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_en, y_pred_en, target_names=['non-sexist', 'sexist']))\n",
    "\n",
    "\n",
    "print(f'Accuracy: {round(100*accuracy_score(y_test_en, y_pred_en), 4)}')\n",
    "print(f'F1 score: {round(100*f1_score(y_test_en, y_pred_en, average=\"macro\"), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-farmer",
   "metadata": {},
   "source": [
    "En español se tiene que:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "respiratory-million",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  non-sexist       0.73      0.78      0.76      1037\n",
      "      sexist       0.79      0.73      0.76      1123\n",
      "\n",
      "    accuracy                           0.76      2160\n",
      "   macro avg       0.76      0.76      0.76      2160\n",
      "weighted avg       0.76      0.76      0.76      2160\n",
      "\n",
      "Accuracy: 75.6944\n",
      "F1 score: 75.6938\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_es, y_pred_es, target_names=['non-sexist', 'sexist']))\n",
    "\n",
    "\n",
    "print(f'Accuracy: {round(100*accuracy_score(y_test_es, y_pred_es), 4)}')\n",
    "print(f'F1 score: {round(100*f1_score(y_test_es, y_pred_es, average=\"macro\"), 4)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
